# -*- coding: utf-8 -*-
"""Hypothesis_testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KCsqOFjiFBbVEsSSU9adedgMLUKNrft-

# Loading Required Libraries
"""

import pandas as pd
from scipy.stats import shapiro, spearmanr
import matplotlib.pyplot as plt
import seaborn as sns

"""# Loading CSV file into the Data Frame"""

df= pd.read_csv('Compund_Cleaned_data.csv')

df.head()

# Normality test for 'Rev_len' and 'compound_sentiment_score'
print("Shapiro Test for Normality")
print("Rev_len:", shapiro(df['Rev_len']))
print("Compound Sentiment Score:", shapiro(df['compound_sentiment_score']))

# Spearman correlation
corr, p_value = spearmanr(df['Rev_len'], df['compound_sentiment_score'])
print("\nSpearman Correlation")
print("Correlation Coefficient:", corr)
print("P-value:", p_value)

# Group by 'Rating' and calculate the mean sentiment score
sentiment_by_rating = df.groupby('Rating')['compound_sentiment_score'].mean()

# Plotting
plt.figure(figsize=(10, 6))
bars = sns.barplot(x=sentiment_by_rating.index, y=sentiment_by_rating.values)
plt.title('Average Sentiment Score by Rating')
plt.xlabel('Rating')
plt.ylabel('Average Sentiment Score')

# Add the data labels on the bars
for bar in bars.patches:
    plt.annotate(format(bar.get_height(), '.2f'),
                 (bar.get_x() + bar.get_width() / 2,
                  bar.get_height()), ha='center', va='center',
                 size=10, xytext=(0, 8),
                 textcoords='offset points')

plt.show()

